{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcs10sQQj/gcYW816v0y/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshziitj/voice-activity-detection-su20/blob/main/M23CSA503/Q2/Q2-TaskA/SU_Assignment01_Q2_Task_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0qWGJTT9lFJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import requests\n",
        "\n",
        "# Define dataset URL\n",
        "dataset_url = \"https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\"\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"./UrbanSound8K\"\n",
        "\n",
        "# Download the dataset\n",
        "tar_file = \"UrbanSound8K.tar.gz\"\n",
        "\n",
        "if not os.path.exists(tar_file):\n",
        "    print(\"Downloading UrbanSound8K dataset...\")\n",
        "    response = requests.get(dataset_url, stream=True)\n",
        "    with open(tar_file, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "# Extract the dataset\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with tarfile.open(tar_file, \"r:gz\") as tar:\n",
        "        tar.extractall(path=dataset_path)  # Extract to target directory\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf /content/UrbanSound8K.tar.gz -C /content/"
      ],
      "metadata": {
        "id": "UsI7Gucd_iAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define window functions\n",
        "def apply_windowing(y, window_type, n_fft=2048):\n",
        "    if window_type == \"hann\":\n",
        "        window = np.hanning(n_fft)\n",
        "    elif window_type == \"hamming\":\n",
        "        window = np.hamming(n_fft)\n",
        "    else:  # Rectangular\n",
        "        window = np.ones(n_fft)\n",
        "\n",
        "    return window\n",
        "\n",
        "# Load an example audio file\n",
        "file_path = \"./UrbanSound8K/audio/fold10/100648-1-0-0.wav\"\n",
        "y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# Apply different windowing techniques\n",
        "windows = [\"hann\", \"hamming\", \"rectangular\"]\n",
        "n_fft = 2048\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i, win_type in enumerate(windows):\n",
        "    window = apply_windowing(y, win_type, n_fft)\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.plot(window)\n",
        "    plt.title(f\"{win_type.capitalize()} Window\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qxdSv7PMADrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(y, sr, n_mfcc=13):\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    return np.mean(mfccs.T, axis=0)  # Compute mean MFCCs for classification\n",
        "\n",
        "# Extract features for each windowing type\n",
        "features = {win: extract_features(y, sr) for win in windows}"
      ],
      "metadata": {
        "id": "WxwKuKdsAfrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "\n",
        "# ------------------------------------------ #\n",
        "# Step 1: Download & Extract UrbanSound8K Dataset\n",
        "# ------------------------------------------ #\n",
        "dataset_url = \"https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\"\n",
        "dataset_path = \"./UrbanSound8K\"\n",
        "tar_file = \"UrbanSound8K.tar.gz\"\n",
        "\n",
        "# Download dataset if not already downloaded\n",
        "if not os.path.exists(tar_file):\n",
        "    print(\"Downloading UrbanSound8K dataset...\")\n",
        "    response = requests.get(dataset_url, stream=True)\n",
        "    with open(tar_file, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "# Extract dataset if not already extracted\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with tarfile.open(tar_file, \"r:gz\") as tar:\n",
        "        tar.extractall(path=dataset_path)\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "# ------------------------------------------ #\n",
        "# Step 2: Define Windowing Techniques\n",
        "# ------------------------------------------ #\n",
        "def apply_windowing(n_fft, window_type):\n",
        "    \"\"\"Applies the selected windowing technique.\"\"\"\n",
        "    if window_type == \"hann\":\n",
        "        return np.hanning(n_fft)\n",
        "    elif window_type == \"hamming\":\n",
        "        return np.hamming(n_fft)\n",
        "    else:  # Rectangular Window\n",
        "        return np.ones(n_fft)\n",
        "\n",
        "# ------------------------------------------ #\n",
        "# Step 3: Generate STFT Spectrograms\n",
        "# ------------------------------------------ #\n",
        "def plot_spectrogram(y, sr, window_type, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Generates and plots spectrogram using STFT.\"\"\"\n",
        "    window = apply_windowing(n_fft, window_type)\n",
        "\n",
        "    # Compute STFT spectrogram\n",
        "    spectrogram = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, window=window)\n",
        "    spectrogram_db = librosa.amplitude_to_db(np.abs(spectrogram))\n",
        "\n",
        "    # Plot and save the spectrogram\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    librosa.display.specshow(spectrogram_db, sr=sr, hop_length=hop_length, cmap=\"magma\")\n",
        "    plt.title(f\"Spectrogram ({window_type.capitalize()} Window)\")\n",
        "    plt.colorbar(format=\"%+2.0f dB\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------ #\n",
        "# Step 4: Extract MFCC Features\n",
        "# ------------------------------------------ #\n",
        "def extract_features(audio_path, window_type=\"hann\", n_mfcc=13, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Extracts MFCC features from audio using different windowing techniques.\"\"\"\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "    # Apply selected windowing technique\n",
        "    window = apply_windowing(n_fft, window_type)\n",
        "\n",
        "    # Generate spectrogram\n",
        "    plot_spectrogram(y, sr, window_type, n_fft, hop_length)\n",
        "\n",
        "    # Extract MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    return np.mean(mfccs.T, axis=0)  # Return mean MFCCs as feature vector\n",
        "\n",
        "# ------------------------------------------ #\n",
        "# Step 5: Extract Features from UrbanSound8K\n",
        "# ------------------------------------------ #\n",
        "audio_folder = os.path.join(dataset_path, \"UrbanSound8K/audio/fold1\")  # Using fold1 for training\n",
        "\n",
        "# Use first 300 samples for better training\n",
        "X = []\n",
        "Y = []\n",
        "window_types = [\"hann\", \"hamming\", \"rectangular\"]\n",
        "\n",
        "for window in window_types:\n",
        "    print(f\"Extracting features using {window.capitalize()} window...\")\n",
        "    for i, filename in enumerate(os.listdir(audio_folder)):\n",
        "        if filename.endswith(\".wav\") and i < 300:  # Increased data size\n",
        "            file_path = os.path.join(audio_folder, filename)\n",
        "            features = extract_features(file_path, window_type=window)\n",
        "            X.append(features)\n",
        "            Y.append(window)  # Assign window type as label\n",
        "\n",
        "# Convert to NumPy array\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# Print feature shape\n",
        "print(\"Feature Shape:\", X.shape)\n",
        "print(\"Label Shape:\", Y.shape)\n",
        "\n",
        "# ------------------------------------------ #\n",
        "# Step 6: Train an SVM Classifier\n",
        "# ------------------------------------------ #\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n",
        "\n",
        "# Split dataset into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train SVM classifier\n",
        "svm = SVC(kernel=\"poly\", degree=3, C=10, gamma=\"scale\")  # Changed kernel to polynomial\n",
        "svm.fit(X_train, Y_train)\n",
        "\n",
        "# ------------------------------------------ #\n",
        "# Step 7: Evaluate Model Performance\n",
        "# ------------------------------------------ #\n",
        "predictions = svm.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, predictions)\n",
        "\n",
        "print(f\"SVM Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print Label Distribution\n",
        "print(\"Label Distribution:\", Counter(Y))"
      ],
      "metadata": {
        "id": "ILIyWlwbAmob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}